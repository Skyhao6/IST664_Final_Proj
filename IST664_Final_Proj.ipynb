{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I have a mind to strike thee ere thou speak'st .\", \"Yet if thou say Antony lives , is well , Or friends with Caesar , or not captive to him , I'll set thee in a shower of gold and hail Rich pearls upon thee .\", \"Madam , he's well .\"]\n",
      "['[start] I have half a mind to hit you before you speak again . [end]', \"[start] But if Antony is alive , healthy , friendly with Caesar , and not Caesar's prisoner , I'll shower you with gold and pearls . [end]\", \"[start] Madam , he's well . [end]\"]\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "# source: modern.nltktok\n",
    "# target: original.nltktok\n",
    "# Task: Translate middle English to modern English\n",
    "source = []\n",
    "target = []\n",
    "\n",
    "with open('original.nltktok', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    source = content.split('\\n')\n",
    "\n",
    "with open('modern.nltktok', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    target = content.split('\\n')\n",
    "\n",
    "# Add start and end tokens to target\n",
    "for i in range(len(target)):\n",
    "    target[i] = '[start] ' + target[i] + ' [end]'\n",
    "\n",
    "# Examples\n",
    "print(source[:3])\n",
    "print(target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min length of source:  0\n",
      "max length of source:  19\n",
      "min length of target:  2\n",
      "max length of target:  18\n"
     ]
    }
   ],
   "source": [
    "# Statistical information\n",
    "min_len = 100000\n",
    "max_len = 0\n",
    "for sentence in source:\n",
    "    if len(sentence) < min_len:\n",
    "        min_len = len(sentence.split())\n",
    "    if len(sentence) > max_len:\n",
    "        max_len = len(sentence.split())\n",
    "\n",
    "print(\"min length of source: \", min_len)\n",
    "print(\"max length of source: \", max_len)\n",
    "\n",
    "min_len = 100000\n",
    "max_len = 0\n",
    "for sentence in target:\n",
    "    if len(sentence) < min_len:\n",
    "        min_len = len(sentence.split())\n",
    "    if len(sentence) > max_len:\n",
    "        max_len = len(sentence.split())\n",
    "\n",
    "print(\"min length of target: \", min_len)\n",
    "print(\"max length of target: \", max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TextVectorization\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "# Vocabulary size of source and target\n",
    "INPUT_MAX_TOKENS = 13000\n",
    "OUTPUT_MAX_TOKENS = 10000\n",
    "# Max length of source and target sentence\n",
    "# If the sentence is shorter than MAX_LEN, it will be padded with 0\n",
    "# If the sentence is longer than MAX_LEN, it will be truncated\n",
    "MAX_LEN = 30\n",
    "batch_size = 64\n",
    "\n",
    "# Build source tokenizer\n",
    "source_tokenizer = TextVectorization(\n",
    "    max_tokens=INPUT_MAX_TOKENS,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_LEN)\n",
    "\n",
    "source_tokenizer.adapt(source)\n",
    "\n",
    "\n",
    "# Build target tokenizer\n",
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "target_tokenizer = TextVectorization(\n",
    "    max_tokens=OUTPUT_MAX_TOKENS,\n",
    "    output_sequence_length=MAX_LEN + 1,\n",
    "    standardize=custom_standardization,\n",
    "    )\n",
    "target_tokenizer.adapt(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_vocab_size:  12443\n",
      "target_vocab_size:  9977\n"
     ]
    }
   ],
   "source": [
    "source_vocab_size = len(source_tokenizer.get_vocabulary())\n",
    "target_vocab_size = len(target_tokenizer.get_vocabulary())\n",
    "print(\"source_vocab_size: \", source_vocab_size)\n",
    "print(\"target_vocab_size: \", target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] what oclock tomorrow shall i send to thee  [end]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "a = \"[start] What o'clock tomorrow Shall I send to thee ? [end]\"\n",
    "print(custom_standardization(a).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Let him be the devil , an he will , I care not .', 'Niggard of question , but of our demands Most free in his reply .', 'Wherefore ?']\n",
      "[\"[start] Let him be the devil if he wants to , I don't care . [end]\", \"[start] He didn't ask questions , but answered ours at length . [end]\", '[start] A reason ? [end]']\n"
     ]
    }
   ],
   "source": [
    "# Randomly shuffle data\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "# Combine the lists into pairs\n",
    "combined_lists = list(zip(source, target))\n",
    "\n",
    "# Shuffle the combined list\n",
    "random.shuffle(combined_lists)\n",
    "\n",
    "# Unzip the shuffled list back into separate lists\n",
    "source, target = zip(*combined_lists)\n",
    "\n",
    "source = list(source)\n",
    "target = list(target)\n",
    "print(source[:3])\n",
    "print(target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of source sentences:  21076\n",
      "Total number of target sentences:  21076\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test set\n",
    "print(\"Total number of source sentences: \", len(source))\n",
    "print(\"Total number of target sentences: \", len(source))\n",
    "\n",
    "source_train = source[:int(len(source)*0.9)]\n",
    "target_train = target[:int(len(target)*0.9)]\n",
    "\n",
    "source_test = source[int(len(source)*0.9):]\n",
    "target_test = target[int(len(target)*0.9):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_word_to_idx = dict([(v,k) for k, v in enumerate(source_tokenizer.get_vocabulary())])\n",
    "src_idx_to_word = dict([(k,v) for k, v in enumerate(source_tokenizer.get_vocabulary())])\n",
    "tar_word_to_idx = dict([(v,k) for k, v in enumerate(target_tokenizer.get_vocabulary())])\n",
    "tar_idx_to_word = dict([(k,v) for k, v in enumerate(target_tokenizer.get_vocabulary())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = source_tokenizer(source_train)\n",
    "decoder_input_data = target_tokenizer(target_train)[:, :-1]\n",
    "decoder_output_data = target_tokenizer(target_train)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18968, 30)\n",
      "(18968, 30)\n",
      "(18968, 30)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:  For us , you know Whose he is we are , and that is Caesar's .\n",
      "Target:  [start] As for us , you know we are Antony's , and he is Caesar's . [end]\n",
      "Decoder input:  tf.Tensor(\n",
      "[   2   24   18   91    4   69   47   28 1318    8   22   14  482    3\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(30,), dtype=int64)\n",
      "Decoder output:  tf.Tensor(\n",
      "[  24   18   91    4   69   47   28 1318    8   22   14  482    3    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(30,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Examples\n",
    "# Encoder input: i have half a mind to hit you before you speak again\n",
    "# Decoder input: [start] i have a mind to strike thee ere thou speakst\n",
    "# Decoder output: i have a mind to strike thee ere thou speakst [end]\n",
    "print(\"Source: \", source_train[664])\n",
    "print(\"Target: \", target_train[664])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Decoder input: \", decoder_input_data[664])\n",
    "print(\"Decoder output: \", decoder_output_data[664])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# d_model\n",
    "embedding_size = 512\n",
    "\n",
    "# dff = d_model * 4\n",
    "dense_dim = 2048\n",
    "\n",
    "# num_heads\n",
    "n_head = 8\n",
    "\n",
    "# num_layers\n",
    "n_layer = 1\n",
    "\n",
    "# dropout rate\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Model\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Positional encoding\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(pos, d_model):\n",
    "\n",
    "    def get_angles(position, i):\n",
    "        return position / np.power(10000., 2. * (i // 2.) / np.float32(d_model))\n",
    "\n",
    "    angle_rates = get_angles(np.arange(pos)[:, np.newaxis],\n",
    "                             np.arange(d_model)[np.newaxis, :])\n",
    "    pe_sin = np.sin(angle_rates[:, 0::2])\n",
    "    pe_cos = np.cos(angle_rates[:, 1::2])\n",
    "    pos_encoding = np.concatenate([pe_sin, pe_cos], axis=-1)\n",
    "    pos_encoding = tf.cast(pos_encoding[np.newaxis, ...], tf.float32)\n",
    "    return pos_encoding\n",
    "\n",
    "# Masking\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, np.newaxis, np.newaxis, :]\n",
    "\n",
    "\n",
    "# Look-ahead mask for decoder\n",
    "def create_look_ahead_mask(size):\n",
    "\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # shape=[seq_len, seq_len]\n",
    "\n",
    "def create_mask(inputs, targets):\n",
    "    encoder_padding_mask = create_padding_mask(inputs)\n",
    "    decoder_padding_mask = create_padding_mask(inputs)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(targets)[1])\n",
    "    decoder_targets_padding_mask = create_padding_mask(targets)\n",
    "    combined_mask = tf.maximum(decoder_targets_padding_mask, look_ahead_mask)\n",
    "    return encoder_padding_mask, combined_mask, decoder_padding_mask\n",
    "\n",
    "# Split tensor into (batch_size, n_head, seq_len, d_head)\n",
    "def splite_tensor(tensor):\n",
    "    shape = tf.shape(tensor)\n",
    "    tensor = tf.reshape(\n",
    "        tensor, shape=[shape[0], -1, n_head, embedding_size//n_head])\n",
    "    tensor = tf.transpose(tensor, perm=[0, 2, 1, 3])\n",
    "    return tensor\n",
    "\n",
    "class MultiHeadAttentionLayer(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "\n",
    "    # Define the layers needed for the computation, including the input shape\n",
    "    def build(self, input_shape):\n",
    "        # Input shape: [batch_size, seq_len, embedding_size] for query, key, value\n",
    "        self.dense_query = layers.Dense(\n",
    "            units=embedding_size, activation='relu')\n",
    "        self.dense_key = layers.Dense(units=embedding_size, activation='relu')\n",
    "        self.dense_value = layers.Dense(\n",
    "            units=embedding_size, activation='relu')\n",
    "\n",
    "        self.layer_norm = layers.LayerNormalization()\n",
    "        super(MultiHeadAttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs\n",
    "        shape = tf.shape(query)\n",
    "\n",
    "        query_dense = self.dense_query(query)\n",
    "        key_dense = self.dense_key(key)\n",
    "        value_dense = self.dense_value(value)\n",
    "\n",
    "        query_dense = splite_tensor(query_dense)\n",
    "        key_dense = splite_tensor(key_dense)\n",
    "        value_dense = splite_tensor(value_dense)\n",
    "\n",
    "        attention = tf.matmul(query_dense, key_dense, transpose_b=True) / \\\n",
    "            tf.math.sqrt(tf.cast(embedding_size, tf.float32))\n",
    "        attention += (mask*-1e9)\n",
    "        attention = tf.nn.softmax(attention)\n",
    "        attention = layers.Dropout(0.1)(attention)\n",
    "        attention = tf.matmul(attention, value_dense)\n",
    "        attention = tf.transpose(attention, [0, 2, 1, 3])\n",
    "        attention = tf.reshape(attention, [shape[0], -1, embedding_size])\n",
    "\n",
    "        attention = self.layer_norm((attention+query))\n",
    "        return attention\n",
    "\n",
    "\n",
    "# Base encoder layer\n",
    "class EncoderLayer(layers.Layer):\n",
    "    def __init__(self, n_head, emb_dim, dense_dim, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attn = MultiHeadAttentionLayer()\n",
    "        self.drop_attn = layers.Dropout(dropout)\n",
    "        self.dense1 = layers.Dense(dense_dim, activation='relu')\n",
    "        self.dense2 = layers.Dense(emb_dim)\n",
    "        self.drop_dense = layers.Dropout(dropout)\n",
    "        self.layer_norm_attn = layers.LayerNormalization()\n",
    "        self.layer_norm_dense = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs,training=None):\n",
    "\n",
    "        encoder_inputs,mask = inputs\n",
    "        att_out = self.attn([encoder_inputs, encoder_inputs,encoder_inputs,mask])\n",
    "        att_out = self.drop_attn(att_out, training=training)\n",
    "        att_out = self.layer_norm_attn(encoder_inputs+att_out)\n",
    "\n",
    "        dense = self.dense1(att_out)\n",
    "        dense = self.dense2(dense)\n",
    "        dense = self.drop_dense(dense, training=training)\n",
    "        x = self.layer_norm_dense(att_out+dense)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Base encoder using multiple encoder layers\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, vocab, emb_dim, dense_dim, n_layers, n_head, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.emb = layers.Embedding(input_dim=vocab, output_dim=emb_dim)\n",
    "        self.pos = positional_encoding(MAX_LEN, emb_dim)\n",
    "\n",
    "        # multi encoder layers\n",
    "        self.encoder_layers = [EncoderLayer(\n",
    "            emb_dim=emb_dim, n_head=n_head, dense_dim=dense_dim, dropout=dropout) for _ in range(n_layers)]\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs,training=None):\n",
    "\n",
    "        encoder_inputs,mask = inputs\n",
    "        # shape=[batch_size, seq_len, d_model]\n",
    "        seq_len = encoder_inputs.shape[1]\n",
    "        # shape=[batch_size, seq_len, d_model]\n",
    "        word_embedding = self.emb(encoder_inputs)\n",
    "        word_embedding *= tf.math.sqrt(tf.cast(self.emb_dim, tf.float32))\n",
    "        emb = word_embedding + self.pos[:, :seq_len, :]\n",
    "\n",
    "        # emb = self.emb(inputs)\n",
    "        x = self.dropout(emb, training=training)\n",
    "        # print('pos:',x)\n",
    "\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            x = encoder_layer([x,mask])\n",
    "            #print('x:',x.shape)\n",
    "        return x\n",
    "\n",
    "    # def compute_mask(self, inputs, mask=None):\n",
    "    #     return self.emb.compute_mask(inputs)\n",
    "\n",
    "class DecoderLayer(layers.Layer):\n",
    "    def __init__(self, n_head, emb_dim, dense_dim, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.attn1 = MultiHeadAttentionLayer()\n",
    "        self.layer_norm_attn1 = layers.LayerNormalization()\n",
    "        self.drop_attn1 = layers.Dropout(dropout)\n",
    "\n",
    "        self.attn2 = MultiHeadAttentionLayer()\n",
    "        self.layer_norm_attn2 = layers.LayerNormalization()\n",
    "        self.drop_attn2 = layers.Dropout(dropout)\n",
    "\n",
    "        self.dense1 = layers.Dense(dense_dim, activation='relu')\n",
    "        self.dense2 = layers.Dense(emb_dim)\n",
    "        self.drop_dense = layers.Dropout(dropout)\n",
    "        self.layer_norm_dense = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs,training=None):\n",
    "        # causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        # if mask is not None:\n",
    "        #     padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "        #     padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        decoder_inputs, encoder_outputs,mask1,mask2 = inputs\n",
    "        att_out1 = self.attn1([decoder_inputs,decoder_inputs,decoder_inputs, mask1])\n",
    "        att_out1 = self.drop_attn1(att_out1, training=training)\n",
    "        att_out1 = self.layer_norm_attn1(decoder_inputs+att_out1)\n",
    "\n",
    "        att_out2 = self.attn2([att_out1,encoder_outputs, encoder_outputs,mask2])\n",
    "        att_out2 = self.drop_attn2(att_out2, training=training)\n",
    "        att_out2 = self.layer_norm_attn2(att_out1+att_out2)\n",
    "\n",
    "        dense = self.dense1(att_out2)\n",
    "        dense = self.dense2(dense)\n",
    "        dense = self.drop_dense(dense, training=training)\n",
    "        x = self.layer_norm_dense(att_out2+dense)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "\n",
    "    def __init__(self, vocab, n_head, n_layers, emb_dim, dense_dim, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.emb = layers.Embedding(input_dim=vocab, output_dim=emb_dim)\n",
    "        self.pos = positional_encoding(MAX_LEN, emb_dim)\n",
    "\n",
    "        self.decoder_layers = [DecoderLayer(\n",
    "            n_head=n_head, emb_dim=emb_dim, dense_dim=dense_dim, dropout=dropout) for _ in range(n_layers)]\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs,training=None):\n",
    "\n",
    "        decoder_inputs, encoder_outputs,mask1,mask2 = inputs\n",
    "\n",
    "        seq_len = decoder_inputs.shape[1]\n",
    "\n",
    "        word_embedding = self.emb(decoder_inputs)\n",
    "        word_embedding *= tf.math.sqrt(tf.cast(self.emb_dim, tf.float32))\n",
    "        emb = word_embedding + self.pos[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(emb, training=training)\n",
    "\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            x = decoder_layer([x, encoder_outputs,mask1,mask2])\n",
    "\n",
    "        return x\n",
    "\n",
    "    # def compute_mask(self, inputs, mask=None):\n",
    "    #     return self.emb.compute_mask(inputs)\n",
    "class Transformer(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Transformer,self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(vocab=INPUT_MAX_TOKENS, n_head=n_head, n_layers=n_layer,\n",
    "                      emb_dim=embedding_size, dense_dim=dense_dim, dropout=dropout)\n",
    "        \n",
    "        self.decoder = Decoder(vocab=OUTPUT_MAX_TOKENS, n_head=n_head, n_layers=n_layer,\n",
    "                      emb_dim=embedding_size, dense_dim=dense_dim, dropout=dropout)\n",
    "        \n",
    "        self.dense = layers.Dense(OUTPUT_MAX_TOKENS, activation='softmax')\n",
    "\n",
    "    def call(self,encoder_inputs,decoder_inputs):\n",
    "        encoder_padding_mask, look_ahead_mask, decoder_padding_mask = create_mask(\n",
    "            encoder_inputs, decoder_inputs)\n",
    "\n",
    "        encoder_outputs = self.encoder([encoder_inputs,encoder_padding_mask])\n",
    "        x = self.decoder([decoder_inputs, encoder_outputs,look_ahead_mask,decoder_padding_mask])\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        decoder_outputs = self.dense(x)\n",
    "        return decoder_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer (Transformer)      (None, 30, 10000)    23477520    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,477,520\n",
      "Trainable params: 23,477,520\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "267/267 [==============================] - 13s 34ms/step - loss: 1.8386 - acc: 0.7275 - val_loss: 1.6352 - val_acc: 0.7477\n",
      "Epoch 2/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 1.4871 - acc: 0.7652 - val_loss: 1.5262 - val_acc: 0.7660\n",
      "Epoch 3/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 1.3267 - acc: 0.7843 - val_loss: 1.4661 - val_acc: 0.7751\n",
      "Epoch 4/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 1.2080 - acc: 0.8000 - val_loss: 1.4511 - val_acc: 0.7778\n",
      "Epoch 5/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 1.1023 - acc: 0.8141 - val_loss: 1.4569 - val_acc: 0.7802\n",
      "Epoch 6/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 1.0107 - acc: 0.8265 - val_loss: 1.5008 - val_acc: 0.7806\n",
      "Epoch 7/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.9275 - acc: 0.8385 - val_loss: 1.5058 - val_acc: 0.7800\n",
      "Epoch 8/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.8505 - acc: 0.8498 - val_loss: 1.5484 - val_acc: 0.7790\n",
      "Epoch 9/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.7790 - acc: 0.8603 - val_loss: 1.5817 - val_acc: 0.7789\n",
      "Epoch 10/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.7139 - acc: 0.8707 - val_loss: 1.6386 - val_acc: 0.7783\n",
      "Epoch 11/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.6667 - acc: 0.8795 - val_loss: 1.6802 - val_acc: 0.7747\n",
      "Epoch 12/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.6309 - acc: 0.8870 - val_loss: 1.7022 - val_acc: 0.7750\n",
      "Epoch 13/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.5997 - acc: 0.8938 - val_loss: 1.7293 - val_acc: 0.7746\n",
      "Epoch 14/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.5722 - acc: 0.9003 - val_loss: 1.7563 - val_acc: 0.7715\n",
      "Epoch 15/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.5448 - acc: 0.9056 - val_loss: 1.7810 - val_acc: 0.7724\n",
      "Epoch 16/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.5221 - acc: 0.9104 - val_loss: 1.7923 - val_acc: 0.7730\n",
      "Epoch 17/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.5022 - acc: 0.9147 - val_loss: 1.8095 - val_acc: 0.7713\n",
      "Epoch 18/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.4870 - acc: 0.9180 - val_loss: 1.8222 - val_acc: 0.7708\n",
      "Epoch 19/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.4700 - acc: 0.9215 - val_loss: 1.8388 - val_acc: 0.7724\n",
      "Epoch 20/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.4577 - acc: 0.9245 - val_loss: 1.8602 - val_acc: 0.7710\n",
      "Epoch 21/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.4475 - acc: 0.9263 - val_loss: 1.8730 - val_acc: 0.7715\n",
      "Epoch 22/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.4360 - acc: 0.9293 - val_loss: 1.8843 - val_acc: 0.7701\n",
      "Epoch 23/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.4270 - acc: 0.9311 - val_loss: 1.9066 - val_acc: 0.7713\n",
      "Epoch 24/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.4208 - acc: 0.9324 - val_loss: 1.9217 - val_acc: 0.7703\n",
      "Epoch 25/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.4131 - acc: 0.9341 - val_loss: 1.9411 - val_acc: 0.7719\n",
      "Epoch 26/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.4078 - acc: 0.9353 - val_loss: 1.9306 - val_acc: 0.7710\n",
      "Epoch 27/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3997 - acc: 0.9371 - val_loss: 1.9413 - val_acc: 0.7713\n",
      "Epoch 28/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.3979 - acc: 0.9372 - val_loss: 1.9617 - val_acc: 0.7691\n",
      "Epoch 29/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.3932 - acc: 0.9383 - val_loss: 1.9685 - val_acc: 0.7698\n",
      "Epoch 30/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3881 - acc: 0.9393 - val_loss: 1.9797 - val_acc: 0.7707\n",
      "Epoch 31/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.3876 - acc: 0.9396 - val_loss: 1.9829 - val_acc: 0.7717\n",
      "Epoch 32/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.3804 - acc: 0.9407 - val_loss: 1.9916 - val_acc: 0.7690\n",
      "Epoch 33/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.3749 - acc: 0.9421 - val_loss: 1.9988 - val_acc: 0.7683\n",
      "Epoch 34/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3731 - acc: 0.9423 - val_loss: 2.0239 - val_acc: 0.7697\n",
      "Epoch 35/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3680 - acc: 0.9434 - val_loss: 2.0157 - val_acc: 0.7701\n",
      "Epoch 36/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3677 - acc: 0.9433 - val_loss: 2.0406 - val_acc: 0.7680\n",
      "Epoch 37/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3651 - acc: 0.9441 - val_loss: 2.0330 - val_acc: 0.7688\n",
      "Epoch 38/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3590 - acc: 0.9451 - val_loss: 2.0375 - val_acc: 0.7691\n",
      "Epoch 39/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3574 - acc: 0.9455 - val_loss: 2.0530 - val_acc: 0.7687\n",
      "Epoch 40/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3536 - acc: 0.9462 - val_loss: 2.0708 - val_acc: 0.7689\n",
      "Epoch 41/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3502 - acc: 0.9467 - val_loss: 2.0859 - val_acc: 0.7679\n",
      "Epoch 42/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3497 - acc: 0.9466 - val_loss: 2.0860 - val_acc: 0.7666\n",
      "Epoch 43/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3484 - acc: 0.9468 - val_loss: 2.0845 - val_acc: 0.7677\n",
      "Epoch 44/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3458 - acc: 0.9474 - val_loss: 2.0936 - val_acc: 0.7672\n",
      "Epoch 45/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.3412 - acc: 0.9482 - val_loss: 2.1226 - val_acc: 0.7685\n",
      "Epoch 46/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3391 - acc: 0.9487 - val_loss: 2.1192 - val_acc: 0.7674\n",
      "Epoch 47/50\n",
      "267/267 [==============================] - 8s 30ms/step - loss: 0.3358 - acc: 0.9487 - val_loss: 2.1315 - val_acc: 0.7659\n",
      "Epoch 48/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.3365 - acc: 0.9489 - val_loss: 2.1444 - val_acc: 0.7668\n",
      "Epoch 49/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.3317 - acc: 0.9499 - val_loss: 2.1439 - val_acc: 0.7660\n",
      "Epoch 50/50\n",
      "267/267 [==============================] - 8s 29ms/step - loss: 0.3320 - acc: 0.9496 - val_loss: 2.1713 - val_acc: 0.7689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1da915a1750>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs = layers.Input((None,))\n",
    "decoder_inputs = layers.Input((None,))\n",
    "\n",
    "transformer = Transformer()\n",
    "decoder_outputs=transformer(encoder_inputs,decoder_inputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', metrics=['acc'],\n",
    "              loss=\"sparse_categorical_crossentropy\")\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_output_data,\n",
    "          validation_split=0.1, epochs=50, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn, decoder_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 76). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespearish\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shakespearish\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('shakespearish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('shakespearish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_tokenizer([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(MAX_LEN):\n",
    "        tokenized_target_sentence = target_tokenizer([decoded_sentence])[:, :-1]\n",
    "        predictions = model(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = tar_idx_to_word[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "source sentence: Thanks , you the valiant of this warlike isle That so approve the Moor .\n",
      "target sentence: [start] Thanks , you brave men who defend this island and respect Othello . [end]\n",
      "translated sentence: [start] thanks you all the brave men have the part of the moor [end]\n",
      "==================================================\n",
      "source sentence: What , so brief ?\n",
      "target sentence: [start] That's it ? [end]\n",
      "translated sentence: [start] so be quick about that [end]\n",
      "==================================================\n",
      "source sentence: So long ?\n",
      "target sentence: [start] As long as that ? [end]\n",
      "translated sentence: [start] so long has it been the long time [end]\n",
      "==================================================\n",
      "source sentence: I shall attend you presently at your tent .\n",
      "target sentence: [start] I'll meet you at your tent . [end]\n",
      "translated sentence: [start] ill wait right away at your tent [end]\n",
      "==================================================\n",
      "source sentence: Good day and happiness , dear Rosalind .\n",
      "target sentence: [start] Good day and happiness to you , darling Rosalind . [end]\n",
      "translated sentence: [start] good night and happiness rosalind [end]\n",
      "==================================================\n",
      "source sentence: Ha ?\n",
      "target sentence: [start] What ? [end]\n",
      "translated sentence: [start] ha [end]\n",
      "==================================================\n",
      "source sentence: Treason !\n",
      "target sentence: [start] Treason ! [end]\n",
      "translated sentence: [start] prayers [end]\n"
     ]
    }
   ],
   "source": [
    "sentences = source_test[-7:]\n",
    "for sentence in sentences:\n",
    "    print(\"=\"*50)\n",
    "    print(\"source sentence:\", sentence)\n",
    "    print(\"target sentence:\", target_test[source_test.index(sentence)])\n",
    "    print(\"translated sentence:\", decode_sequence(sentence))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
